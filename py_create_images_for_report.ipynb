{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produced Gas Generate Visuals and Create Tables\n",
    "Original Author: *Eric Jack*  <br> Modified by: *Monique Beaulieu*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Builds on *py_get_tag_data.ipynb* and generates visuals and analysis tables for a daily Produced Gas report:\n",
    "- Primarily using pad-level produced gas (PG) and well frequency data.\n",
    "- Uses pad-level PG (df_all_data_pads_pg) for ROC and plotting\n",
    "- Pulls well-level data: esp_frequency, temp_tubing, and casing_valve\n",
    "<br>\n",
    "\n",
    "\n",
    "Gives a high-level overview of how field emulsion compares with total gas production and constraints "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-24 05:55:00\n"
     ]
    }
   ],
   "source": [
    "#!\"C:\\Production_Python_Scripts\\Produced Gas Daily Report/venv_pg_daily_email_report/Scripts/python.exe\"\n",
    "from cmath import nan\n",
    "import string\n",
    "from unicodedata import name\n",
    "import json\n",
    "\n",
    "from pyparsing import line\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime as dt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "# import custom code from py_get_tag_data\n",
    "import py_get_tag_data\n",
    "# import py_create_pdf_report\n",
    "import plotly.io as pio\n",
    "import dateutil.relativedelta\n",
    "from scipy.stats import linregress\n",
    "\n",
    "import traceback\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Global rootDir and time parameters for the data window: endDate is today at 5:55 AM.\n",
    "- Initialize a basic logging system (Log.txt) to track script starts/completions/errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "under root dir\n"
     ]
    }
   ],
   "source": [
    "pio.kaleido.scope.mathjax = None\n",
    "\n",
    "rootDir = r\"C:\\Users\\MoBeaulieu\\OneDrive - Suncor Energy Inc\\Documents\\python_projects_local\\pg_script\"\n",
    "print('under root dir')\n",
    "\n",
    "f = open(rootDir + \"/Log.txt\",\"a+\")\n",
    "f.write(\"\\r\\n\")\n",
    "f.write(\"\\r\\n\")\n",
    "f.write(\"-----------------------------------\\r\\n\")\n",
    "str_msg = str(dt.datetime.today()) + \" - Starting Code\"\n",
    "f.write(str_msg + \"\\r\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "\t#attempts to create df out of pickle. If not exists it will pull data and recreate pickle\n",
    "\tprint('in try')\n",
    "\t#padInput = input(\"Enter pad number ex. '103' and hit enter.\")\n",
    "\n",
    "\trootDir = r\"C:\\Users\\MoBeaulieu\\OneDrive - Suncor Energy Inc\\Documents\\python_projects_local\\pg_script\"\n",
    "\n",
    "\tendDate = dt.datetime.combine(dt.date.today (), dt.time(hour=5, minute=55))\n",
    "\tpg_roc_lookback_list = [2,7,14]\n",
    "\n",
    "\tdf_pg_roc_data = pd.DataFrame()\n",
    "\tdf_pg_roc_data['mp'] = ''\n",
    "\tfor i in pg_roc_lookback_list:\n",
    "\t\tdf_pg_roc_data[str(i) + 'd'] = nan\n",
    "\n",
    "\n",
    "\t\n",
    "\t# get SRU, plant process gas, and field emulsion data for SRU summary plot\n",
    "\tdf = py_get_tag_data.create_sru_plot_png() # Pulls emulsion, plant gas, and SRU gas data.\n",
    "\t# Plots: Emulsion on a secondary y-axis, Plant gas and reservoir gas on teh primary y-axis, Constraint lines at 12,700 and 10,500 m3/h\n",
    "\t\n",
    "\tprint(df)\n",
    "\n",
    "\tfig_sru_plot = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "\tfig_sru_plot.add_trace(go.Scatter(\n",
    "\n",
    "\t\tx=df['date'].tolist(), y=df['field_emul'].tolist(),\n",
    "\t\thoverinfo='x+y',\n",
    "\t\tmode='lines',\n",
    "\t\tname = 'Emulsion (2nd)',\n",
    "\t\tline=dict(width=1.5, color='rgb(0, 0, 0)', ),\n",
    "\t\t),\n",
    "\t\tsecondary_y = True\n",
    "\t)\n",
    "\n",
    "\tfig_sru_plot.add_trace(go.Scatter(\n",
    "\n",
    "\t\tx=df['date'].tolist(), y=df['plant_sum'].tolist(),\n",
    "\t\thoverinfo='x+y',\n",
    "\t\tmode='lines',\n",
    "\t\tname = 'Plant Gas (1st)',\n",
    "\t\tline=dict(width=1, color='blue'),\n",
    "\t\tstackgroup='pg'\n",
    "\t\t), # define stack group\n",
    "\t\tsecondary_y = False\n",
    "\t)\n",
    "\tfig_sru_plot.add_trace(go.Scatter(\n",
    "\n",
    "\t\tx=df['date'].tolist(), y=df['res_gas'].tolist(),\n",
    "\t\thoverinfo='x+y',\n",
    "\t\tmode='lines',\n",
    "\t\tname = 'Reservoir Gas (1st)',\n",
    "\t\tline=dict(width=1, color='red'),\n",
    "\t\tstackgroup='pg'\n",
    "\t\t), # define stack group\n",
    "\t\tsecondary_y = False\n",
    "\t)\n",
    "\n",
    "\n",
    "\n",
    "\tsru_constraint_data = [12700]*len(df['date'].tolist())\n",
    "\n",
    "\tfig_sru_plot.add_trace(go.Scatter(\n",
    "\t\tx=df['date'].tolist(), y=sru_constraint_data,\n",
    "\t\thoverinfo='x+y',\n",
    "\t\tmode='lines',\n",
    "\t\tname = 'SRU Constraint (1st)',\n",
    "\t\tline=dict(width=5, color='darkred', dash='dash'),\n",
    "\t\t), # define stack group\n",
    "\t\tsecondary_y = False\n",
    "\t)\n",
    "\n",
    "\tsru_constraint_data_2 = [10500]*len(df['date'].tolist())\n",
    "\n",
    "\tfig_sru_plot.add_trace(go.Scatter(\n",
    "\t\tx=df['date'].tolist(), y=sru_constraint_data_2,\n",
    "\t\thoverinfo='x+y',\n",
    "\t\tmode='lines',\n",
    "\t\tname = 'SRU Constraint (1st)',\n",
    "\t\tline=dict(width=5, color='orange', dash='dash'),\n",
    "\t\t), # define stack group\n",
    "\t\tsecondary_y = False\n",
    "\t)\n",
    "\n",
    "\n",
    "\tfig_sru_plot.update_yaxes(title_text=\"Produced Gas (m3/h)\", titlefont = dict(size = 20), tickfont = dict(size=20), secondary_y=False)\n",
    "\tfig_sru_plot.update_yaxes(title_text=\"Emulsion (m3/h)\",titlefont = dict(size = 20), tickfont = dict(size=20), secondary_y=True)\n",
    "\t#fig_sru_plot.update_layout(yaxis_range=(0, 100))\n",
    "\n",
    "\tfig_sru_plot.update_layout(width=1200, height = 500, margin=dict(l= 0, r= 0, t=0, b=0))\n",
    "\tfig_sru_plot.update_layout(legend=dict(yanchor=\"top\", y=0.20, xanchor=\"left\", x=0))\n",
    "\t#fig_sru_plot.write_image(rootDir + \"/prod_report_images/sru_plot.png\", format=\"png\", scale=3, engine=\"kaleido\") \n",
    "\n",
    "#############################################################################################################################################################################################\n",
    "\t\n",
    "\tprint('about to enter get well status data')\n",
    "\t# well status vizualization\n",
    "\tdf = py_get_tag_data.create_cut_wells_status_data()\n",
    "\t# Loads a list of \"high gas offender\" wells from Excel\n",
    "\t# Pulls current ESP frequency values and compares to low/high thresholds\n",
    "\t# Plots markers: Red for low/high bounds, Black for current value (only if active)\n",
    "\n",
    "\tprint(df)\n",
    "\tprint('well status data df should be above')\n",
    "\n",
    "\tfig_well_cuts = go.Figure()\n",
    "\n",
    "\tfor index, row in df.iterrows():\n",
    "\n",
    "\t\twell = row['well']\n",
    "\t\tlow = row['low_freq']\n",
    "\t\thigh = row['high_freq']\n",
    "\t\tcurr = row['current_freq']\n",
    "\n",
    "\t\t\n",
    "\t\tif curr < 10:\n",
    "\t\t\tx_text = well + '<br>(offline)'\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\tx_text = well\n",
    "\n",
    "\n",
    "\n",
    "\t\tfig_well_cuts.add_trace(go.Scatter(\n",
    "\t\t\tx=[x_text], y=[high],\n",
    "\t\t\tmode='markers+text',\n",
    "\t\t\tmarker=dict(\n",
    "\t\t\t\tcolor='red',\n",
    "\t\t\t\tsize=15,\n",
    "\t\t\t\tline = dict(\n",
    "\t\t\t\t\tcolor = 'red',\n",
    "\t\t\t\t\twidth = 4\n",
    "\t\t\t\t),\n",
    "\t\t\t),\n",
    "\t\t\ttext = [high],\n",
    "\t\t\ttextposition=\"top center\",\n",
    "\t\t\ttextfont=dict(\n",
    "\t\t\t\tfamily=\"sans serif\",\n",
    "\t\t\t\tsize=20,\n",
    "\t\t\t\tcolor='red'\n",
    "\t\t\t),\n",
    "\t\t\tmarker_symbol = 'line-ew', \n",
    "\t\t\tname=well + ' high', \n",
    "\t\t\tlegendgroup = well)\n",
    "\t\t)\n",
    "\n",
    "\t\tfig_well_cuts.add_trace(go.Scatter(\n",
    "\t\t\tx=[x_text], y=[low],\n",
    "\t\t\tmode='markers+text',\n",
    "\t\t\tmarker=dict(\n",
    "\t\t\t\tcolor='red',\n",
    "\t\t\t\tsize=15,\n",
    "\t\t\t\tline = dict(\n",
    "\t\t\t\t\tcolor = 'red',\n",
    "\t\t\t\t\twidth = 4\n",
    "\t\t\t\t),\n",
    "\t\t\t),\n",
    "\t\t\ttext = [low],\n",
    "\t\t\ttextposition=\"bottom center\",\n",
    "\t\t\ttextfont=dict(\n",
    "\t\t\t\tfamily=\"sans serif\",\n",
    "\t\t\t\tsize=20,\n",
    "\t\t\t\tcolor='red'\n",
    "\t\t\t),\n",
    "\t\t\tmarker_symbol = 'line-ew', \n",
    "\t\t\tname=well + ' low', \n",
    "\t\t\tlegendgroup = well)\n",
    "\t\t)\n",
    "\n",
    "\t\t#adding this trace at the end so it is over top of the high/low markers. \n",
    "\t\tif curr >= 10:\n",
    "\t\t\tfig_well_cuts.add_trace(go.Scatter(\n",
    "\t\t\t\tx=[x_text], y=[curr],\n",
    "\t\t\t\tmode='markers+text',\n",
    "\t\t\t\tmarker=dict(\n",
    "\t\t\t\t\tcolor='black',\n",
    "\t\t\t\t\tsize=20,\n",
    "\t\t\t\t\tline = dict(\n",
    "\t\t\t\t\t\tcolor = 'black',\n",
    "\t\t\t\t\t\twidth = 4\n",
    "\t\t\t\t\t),\n",
    "\t\t\t\t),\n",
    "\t\t\t\ttext = [curr],\n",
    "\t\t\t\ttextposition=\"middle right\",\n",
    "\t\t\t\ttextfont=dict(\n",
    "\t\t\t\t\tfamily=\"sans serif\",\n",
    "\t\t\t\t\tsize=20,\n",
    "\t\t\t\t\tcolor='black'\n",
    "\t\t\t\t),\n",
    "\t\t\t\tmarker_symbol = 'line-ew', \n",
    "\t\t\t\tname=well + ' current', \n",
    "\t\t\t\tlegendgroup = well)\n",
    "\t\t\t)\n",
    "\n",
    "\n",
    "\tfig_well_cuts.update_yaxes(title_text=\"Freq (hz)\", titlefont = dict(size = 20), tickfont = dict(size=20))\n",
    "\tfig_well_cuts.update_xaxes(tickfont = dict(size=15))\n",
    "\tfig_well_cuts.update_layout(width=1500, height = 180, showlegend=False, margin=dict(l= 0, r= 0, t=0, b=0))\n",
    "\tfig_well_cuts.update_yaxes(range=[30, 65])\n",
    "\t#fig_well_cuts.write_image(rootDir + \"/prod_report_images/well_cuts_plot.png\", format=\"png\", scale=3, engine=\"kaleido\") \n",
    "\n",
    "\t#############################################################################################################################################################################################\n",
    "\n",
    "\tmeasurementPoints = ['P91_92', 'P105', 'P106', 'P107', 'P108', 'P110', 'P114', 'P115', 'P116', 'P117', 'P112', 'P121']\n",
    "\t#measurementPoints = ['P106']\n",
    "\n",
    "\tall_events = []\n",
    "\t# Main processing loop over pads\n",
    "\tfor mp in measurementPoints:\n",
    "\t\t# Loads pad and well pickle files (or regenerates them if missing)\n",
    "\t\t# Filters data into: esp_frequency (to detect trips, starts, speedups), temp_tubing (to detect deadhead/NFE events), and casing_valve (to get 48hr avg casing valve position)\n",
    "\n",
    "\t\twellsPickleName = 'data_wells_'+ str(mp) + '.pkl'\n",
    "\t\tpadsPickleName = 'data_pads_'+ str(mp) + '.pkl'\n",
    "\n",
    "\n",
    "\t\tprodMode = False\n",
    "\t\tif prodMode == True:\n",
    "\t\t\tpy_get_tag_data.function_get_pi_data_create_pickle_wells(str(mp))\n",
    "\t\t\tdf_all_data_wells = pd.read_pickle(rootDir + \"/prod_pickle_files/\" + wellsPickleName)\n",
    "\n",
    "\t\t\tif mp == 'P91_92':\n",
    "\t\t\t\tpy_get_tag_data.function_get_pi_data_create_pickle_P9192()\n",
    "\t\t\telse:\n",
    "\t\t\t\tpy_get_tag_data.function_get_pi_data_create_pickle_pads(str(mp))\n",
    "\n",
    "\t\t\tdf_all_data_pads = pd.read_pickle(rootDir + \"/prod_pickle_files/\" + padsPickleName)\n",
    "\n",
    "\t\telse:\n",
    "\n",
    "\t\t\ttry:\n",
    "\t\t\t\tdf_all_data_wells = pd.read_pickle(rootDir + \"/prod_pickle_files/\" + wellsPickleName)\n",
    "\t\t\texcept:\n",
    "\t\t\t\t\n",
    "\t\t\t\tpy_get_tag_data.function_get_pi_data_create_pickle_wells(str(mp))\n",
    "\t\t\t\tdf_all_data_wells = pd.read_pickle(rootDir + \"/prod_pickle_files/\" + wellsPickleName)\n",
    "\n",
    "\t\t\ttry:\n",
    "\t\t\t\tdf_all_data_pads = pd.read_pickle(rootDir + \"/prod_pickle_files/\" + padsPickleName)\n",
    "\t\t\texcept:\n",
    "\n",
    "\t\t\t\tif mp == 'P91_92':\n",
    "\t\t\t\t\tpy_get_tag_data.function_get_pi_data_create_pickle_P9192()\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tpy_get_tag_data.function_get_pi_data_create_pickle_pads(str(mp))\n",
    "\n",
    "\t\t\t\tdf_all_data_pads = pd.read_pickle(rootDir + \"/prod_pickle_files/\" + padsPickleName)\n",
    "\n",
    "\n",
    "\t\tuniqueAttributes = df_all_data_wells['attribute'].unique()\n",
    "\n",
    "\t\tdf_all_data_wells_esp_frequency = df_all_data_wells.loc[df_all_data_wells['attribute'] == 'esp_frequency']\n",
    "\t\tdf_all_data_wells_esp_frequency_pivot = df_all_data_wells_esp_frequency.reset_index().pivot_table(index='date', columns='well', values='value')\n",
    "\n",
    "\t\tdf_all_data_wells_temp_tubing = df_all_data_wells.loc[df_all_data_wells['attribute'] == 'temp_tubing']\n",
    "\t\tdf_all_data_wells_temp_tubing_pivot = df_all_data_wells_temp_tubing.reset_index().pivot_table(index='date', columns='well', values='value')\n",
    "\n",
    "\n",
    "\t\tdf_all_data_wells_casing_valve_test_status=df_all_data_wells.loc[df_all_data_wells['attribute'] == 'casing_valve']\n",
    "\t\t\n",
    "\t\twells = df_all_data_wells_esp_frequency_pivot.columns\n",
    "\n",
    "\t\tdf_all_data_pads_pg = df_all_data_pads.loc[df_all_data_pads['attribute'] == 'produced_gas']\n",
    "\t\t#df_all_data_pads_emulsion= df_all_data_pads.loc[df_all_data_pads['attribute'] == 'real_time_pad_flow']\n",
    "\n",
    "\n",
    "\t\t#script that will take the linear regression (rate of change) over different time periods for produced gas and store in a data frame\n",
    "\t\t# For each pad: filters produced_gas from pad-level data, looks back 2, 7, and 14 days, applies linear regression (linregress) to determine daily rate of change (slope), saves to a table\n",
    "\t\t\t\n",
    "\t\t#temp_df = pd.DataFrame(data={'mp': [mp]})\n",
    "\t\tdf_roc_data_temp = pd.DataFrame()\n",
    "\t\tdf_roc_data_temp['mp'] = [mp]\n",
    "\t\tfor dayslookback in pg_roc_lookback_list:\n",
    "\n",
    "\t\t\tdf_temp =df_all_data_pads_pg[~(df_all_data_pads_pg['date'] < (endDate - dateutil.relativedelta.relativedelta(days = dayslookback)))]\n",
    "\n",
    "\n",
    "\t\t\tiCount = 0\n",
    "\t\t\tstep = 0.6\n",
    "\t\t\ttimeHourlyStep = []\n",
    "\t\t\tfor i in df_temp['date'].tolist():\n",
    "\t\t\t\ttimeHourlyStep.append(step*iCount)\n",
    "\t\t\t\tiCount = iCount +1\n",
    "\t\t\t\n",
    "\n",
    "\t\t\ttry:\n",
    "\t\t\t\troc = linregress(timeHourlyStep, df_temp['value'].tolist()).slope\n",
    "\t\t\t\tdf_roc_data_temp[str(dayslookback)+'d'] = [round(roc*24, 1)]\n",
    "\t\t\texcept:\n",
    "\t\t\t\tdf_roc_data_temp[str(dayslookback)+'d'] = 'err'\n",
    "\n",
    "\n",
    "\t\tdf_pg_roc_data = pd.concat([df_pg_roc_data, df_roc_data_temp])\n",
    "\n",
    "\t\t\n",
    "\n",
    "\n",
    "\t\ttrip_well_names = []\n",
    "\n",
    "\t\t#fig = go.Figure()\n",
    "\t\tfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "\t\tfig.add_trace(go.Scatter(\n",
    "\t\t\tx=df_all_data_pads_pg['date'].tolist(),\n",
    "\t\t\ty=df_all_data_pads_pg['value'].tolist(),\n",
    "\t\t\tmode='lines',\n",
    "\t\t\tline=dict(\n",
    "\t\t\t\tcolor='black',\n",
    "\t\t\t\t),\n",
    "\t\t\tname='PG'),\n",
    "\t\t\tsecondary_y=False, \n",
    "\t\t)\n",
    "\n",
    "\t\t# fig.add_trace(go.Scatter(\n",
    "\t\t# \tx=df_all_data_pads_emulsion['date'].tolist(),\n",
    "\t\t# \ty=df_all_data_pads_emulsion['value'].tolist(),\n",
    "\t\t# \tmode='lines',\n",
    "\t\t# \tline=dict(\n",
    "\t\t# \t\tcolor='yellow',\n",
    "\t\t# \t\t),\n",
    "\t\t# \tname='Emulsion'),\n",
    "\t\t# \tsecondary_y=True, \n",
    "\t\t# )\n",
    "\n",
    "\t\t\n",
    "\n",
    "\t\ttrip_dates = []\n",
    "\t\ttrip_desc = []\n",
    "\t\ttrip_pgVal = []\n",
    "\n",
    "\t\tstart_dates=[]\n",
    "\t\tstart_desc = []\n",
    "\t\tstart_pgVal = []\n",
    "\n",
    "\t\t#df_casing_valve_postiion = pd.DataFrame(columns = ['well', '48hr']))\n",
    "\t\t# = pd.DataFrame(data={'well': trip_dates, 'vals': trip_desc})\n",
    "\t\twell_csg_valve_lookback_list = [2, 7, 14]\n",
    "\t\tdf_csg_valve_data= pd.DataFrame()\n",
    "\t\tdf_csg_valve_data['Well'] = ''\n",
    "\t\tfor i in well_csg_valve_lookback_list:\n",
    "\t\t\tdf_csg_valve_data[str(i) + 'd'] = nan\n",
    "\t\t\n",
    "\t\ttempThreasholdForFlowing = 140\n",
    "\t\tfor well in wells:\n",
    "\n",
    "\t\t\tprint(well)\n",
    "\n",
    "\t\t\t#get the 48hour average casing valve position and append to a dataframe\n",
    "\t\t\tdf_csg = df_all_data_wells_casing_valve_test_status.loc[df_all_data_wells['well'] == well]\n",
    "\n",
    "\t\t\tdf_csg_valve_data_temp = pd.DataFrame()\n",
    "\t\t\tdf_csg_valve_data_temp['Well'] = [well]\n",
    "\t\t\tfor dayslookback in well_csg_valve_lookback_list:\n",
    "\n",
    "\t\t\t\tdf_temp =df_csg[~(df_csg['date'] < (endDate - dateutil.relativedelta.relativedelta(days = dayslookback)))]\n",
    "\t\t\t\tlist_vals = df_temp['value'].tolist()\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tavg_valve_pos = sum(list_vals)/len(list_vals)\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tavg_valve_pos = 0\n",
    "\t\t\t\tdf_csg_valve_data_temp[str(dayslookback)+'d'] = [round(avg_valve_pos, 1)]\n",
    "\n",
    "\t\t\tdf_csg_valve_data = pd.concat([df_csg_valve_data, df_csg_valve_data_temp])\n",
    "\n",
    "\n",
    "\t\t\t# ESP event detection: loop through each well and each time step\n",
    "\t\t\t# Tracks ESP frequency changes to identify: Trips: sudden drops (delta <-20Hz), Starts: sudden jumps (delta > +20hz)\n",
    "\t\t\t# Deadhead/NFE: Checks if tubing temperature is dropping quickly while ESP is running , triggered by a 4-hr slope <-5degC and previous temp >140 degC \n",
    "\t\t\t# Speedups: If ESP frequency gradually increases over 10 points (but less than +25hz total) is marked as a ramp-up \n",
    "\t\t\t# stored in all_events and plotted in PG plot\n",
    "\t\t\t\n",
    "\t\t\tlastEventTrip = False #for deadehad logic\n",
    "\t\t\tdeadheadEventDetected = False\n",
    "\t\t\tspeedUpEventsDetected = False\n",
    "\t\t\t\n",
    "\t\t\t#x_anno = []\n",
    "\t\t\t#y_anno = []\n",
    "\t\t\t#text_anno = []\n",
    "\n",
    "\t\t\tfor rowNum, (index, row) in enumerate(df_all_data_wells_esp_frequency_pivot.iterrows()):\n",
    "\n",
    "\n",
    "\t\t\t\tif rowNum ==0:\n",
    "\t\t\t\t\tprevVal = row[well]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tcurrentVal = row[well]\n",
    "\t\t\t\t\tdiff = currentVal-prevVal\n",
    "\n",
    "\t\t\t\t\tif rowNum > 5 and deadheadEventDetected == True:\n",
    "\t\t\t\t\t\t#check to see if well has started flowing again\n",
    "\t\t\t\t\t\t#(established by the last 5 points being greater than flowing temp threashhold and then cancel deadhead event true so that it can be detected again)\n",
    "\t\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\t\tdateDiffLastDeadhead = df_all_data_wells_esp_frequency_pivot.index.tolist()[rowNum] - lastDeadheadDate\n",
    "\t\t\t\t\t\t\tdaysDiff = dateDiffLastDeadhead.days\n",
    "\t\t\t\t\t\t\ttempList=[]\n",
    "\t\t\t\t\t\t\t#print(rowNum)\n",
    "\t\t\t\t\t\t\t#print(df_all_data_wells_temp_tubing_pivot[well])\n",
    "\t\t\t\t\t\t\t#print(len(df_all_data_wells_temp_tubing_pivot[well].tolist()))\n",
    "\t\t\t\t\t\t\t#print('list length above')\n",
    "\n",
    "\t\t\t\t\t\t\t#print('length of esp pivot table below')\n",
    "\t\t\t\t\t\t\t#print(df_all_data_wells_esp_frequency_pivot[well])\n",
    "\t\t\t\t\t\t\t#print('------')\n",
    "\t\t\t\t\t\t\t#print(df_all_data_wells_esp_frequency_pivot)\n",
    "\n",
    "\t\t\t\t\t\t\tfor i in range(1,6):\n",
    "\t\t\t\t\t\t\t\t#print(rowNum)\n",
    "\t\t\t\t\t\t\t\ttempList.append(df_all_data_wells_temp_tubing_pivot[well].tolist()[rowNum-i])\n",
    "\n",
    "\t\t\t\t\t\t\tif all(i >= (tubingTempPriorToDeadhead-10) for i in tempList) and daysDiff >1:\n",
    "\t\t\t\t\t\t\t\tdeadheadEventDetected = False\n",
    "\t\t\t\t\t\texcept:\n",
    "\t\t\t\t\t\t\tdeadheadEventDetected = False\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t#print(tubingTempPriorToDeadhead)\n",
    "\t\t\t\t\t\t#print(tempList)\n",
    "\t\t\t\t\t\t#print('curr date', df_all_data_wells_esp_frequency_pivot.index.tolist()[rowNum])\n",
    "\t\t\t\t\t\t#print('lastdeadhead date', dateDiffLastDeadhead)\n",
    "\t\t\t\t\t\t#print(daysDiff)\n",
    "\t\t\t\t\t\t#print(deadheadEventDetected)\n",
    "\n",
    "\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t#input('')\n",
    "\t\t\t\t\t\t\n",
    "\n",
    "\n",
    "\t\t\t\t\tif diff < -20:\n",
    "\t\t\t\t\t\tlastEventTrip = True\n",
    "\t\t\t\t\t\tdeadheadEventDetected = False\n",
    "\t\t\t\t\t\ttrip_desc_str = 'ESP Trip', index, well, ' ESP went from ', prevVal, 'hz to ', currentVal, 'hz'\n",
    "\t\t\t\t\t\tprint(trip_desc_str)\n",
    "\t\t\t\t\t\tdate = df_all_data_wells_esp_frequency_pivot.index.tolist()[rowNum]\n",
    "\t\t\t\t\t\tannotation = well + ' trip'\n",
    "\t\t\t\t\t\t#print(df_all_data_pads_pg)\n",
    "\t\t\t\t\t\ttrip_dates.append(date)\n",
    "\t\t\t\t\t\ttrip_desc.append(annotation)\n",
    "\t\t\t\t\t\tall_events.append({'well':well, 'date': date.strftime('%Y-%m-%d %X'), 'desc': annotation}) #############\n",
    "\n",
    "\t\t\t\t\t\t#x_anno.append(date)\n",
    "\t\t\t\t\t\t#y_anno.append(df_all_data_pads_pg['value'].loc[df_all_data_pads_pg['date']==date].tolist()[0])\n",
    "\t\t\t\t\t\t#text_anno.append(well)\n",
    "\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tfig.add_trace(go.Scatter(\n",
    "\t\t\t\t\t\t\tx=[date], y=[df_all_data_pads_pg['value'].loc[df_all_data_pads_pg['date']==date].tolist()[0]],\n",
    "\t\t\t\t\t\t\tmode='markers + text',\n",
    "\t\t\t\t\t\t\tmarker=dict(\n",
    "\t\t\t\t\t\t\t\tcolor='red',\n",
    "\t\t\t\t\t\t\t\tsize=10,\n",
    "\t\t\t\t\t\t\t),\n",
    "\t\t\t\t\t\t\ttext = [well],\n",
    "\t\t\t\t\t\t\ttextposition=\"middle left\",\n",
    "\t\t\t\t\t\t\ttextfont=dict(\n",
    "\t\t\t\t\t\t\t\tfamily=\"sans serif\",\n",
    "\t\t\t\t\t\t\t\tsize=8,\n",
    "\t\t\t\t\t\t\t\tcolor='red'\n",
    "\t\t\t\t\t\t\t),\n",
    "\t\t\t\t\t\t\tmarker_symbol = 'triangle-down', \n",
    "\t\t\t\t\t\t\tname=annotation, \n",
    "\t\t\t\t\t\t\tlegendgroup = well),\n",
    "\t\t\t\t\t\t\tsecondary_y=False,\n",
    "\t\t\t\t\t\t)\n",
    "\n",
    "\t\t\t\t\t\t# fig.add_annotation(text=well, x=date, y=df_all_data_pads_pg['value'].loc[df_all_data_pads_pg['date']==date].tolist()[0], showarrow=False, textangle=-90,\n",
    "\t\t\t\t\t\t# \tfont=dict(\n",
    "\t\t\t\t\t\t# \t\tfamily=\"sans serif\",\n",
    "\t\t\t\t\t\t# \t\tsize=8,\n",
    "\t\t\t\t\t\t# \t\tcolor='red'\n",
    "\t\t\t\t\t\t# \t), yshift = -20)\n",
    "\n",
    "\n",
    "\t\t\t\t\telif diff >20:\n",
    "\t\t\t\t\t\tlastEventTrip = False\n",
    "\t\t\t\t\t\tdeadheadEventDetected = False\n",
    "\t\t\t\t\t\ttrip_desc_str = 'ESP Start', index, well, ' ESP went from ', prevVal, 'hz to ', currentVal, 'hz'\n",
    "\t\t\t\t\t\tprint(trip_desc_str)\n",
    "\t\t\t\t\t\tdate = df_all_data_wells_esp_frequency_pivot.index.tolist()[rowNum]\n",
    "\t\t\t\t\t\tannotation = well + ' start'\n",
    "\t\t\t\t\t\tstart_dates.append(date)\n",
    "\t\t\t\t\t\tstart_desc.append(annotation)\n",
    "\t\t\t\t\t\tall_events.append({'well':well, 'date': date.strftime('%Y-%m-%d %X'), 'desc': annotation}) #############\n",
    "\n",
    "\t\t\t\t\t\t\n",
    "\n",
    "\n",
    "\t\t\t\t\t\tfig.add_trace(go.Scatter(\n",
    "\t\t\t\t\t\t\tx=[date], y=[df_all_data_pads_pg['value'].loc[df_all_data_pads_pg['date']==date].tolist()[0]],\n",
    "\t\t\t\t\t\t\tmode='markers + text',\n",
    "\t\t\t\t\t\t\tmarker=dict(\n",
    "\t\t\t\t\t\t\t\tcolor='green',\n",
    "\t\t\t\t\t\t\t\tsize=10,\n",
    "\t\t\t\t\t\t\t),\n",
    "\t\t\t\t\t\t\ttext = [well],\n",
    "\t\t\t\t\t\t\ttextposition=\"middle left\",\n",
    "\t\t\t\t\t\t\ttextfont=dict(\n",
    "\t\t\t\t\t\t\t\tfamily=\"sans serif\",\n",
    "\t\t\t\t\t\t\t\tsize=8,\n",
    "\t\t\t\t\t\t\t\tcolor='green'\n",
    "\t\t\t\t\t\t\t),\n",
    "\t\t\t\t\t\t\tmarker_symbol = 'triangle-up',\n",
    "\t\t\t\t\t\t\tname=annotation, \n",
    "\t\t\t\t\t\t\tlegendgroup = well),\n",
    "\t\t\t\t\t\t\tsecondary_y=False,\n",
    "\t\t\t\t\t\t)\n",
    "\n",
    "\t\t\t\t\t\t# fig.add_annotation(text=well, x=date, y=df_all_data_pads_pg['value'].loc[df_all_data_pads_pg['date']==date].tolist()[0], showarrow=False, textangle=-90,\n",
    "\t\t\t\t\t\t# \tfont=dict(\n",
    "\t\t\t\t\t\t# \t\tfamily=\"sans serif\",\n",
    "\t\t\t\t\t\t# \t\tsize=8,\n",
    "\t\t\t\t\t\t# \t\tcolor='green'\n",
    "\t\t\t\t\t\t# \t), yshift = 20)\n",
    "\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\telif lastEventTrip ==False: #no esp trip or start detected. Determine if deadhead event is occuring. \n",
    "\t\t\t\t\t\t#create better logic. Right now the +40 = 4hrs at 6min data intervale\n",
    "\t\t\t\t\t\tif rowNum >40:\n",
    "\t\t\t\t\t\t\tif deadheadEventDetected != True:\n",
    "\t\t\t\t\t\t\t\ttry: #it will not be able to perform this check on the first 4 hours of data.\n",
    "\t\t\t\t\t\t\t\t\tif df_all_data_wells_temp_tubing_pivot[well].tolist()[rowNum-40] > tempThreasholdForFlowing: #logic added so that wells that are offline with temps are not \n",
    "\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\t\t\ttemp_tubing_4hr_slope=(df_all_data_wells_temp_tubing_pivot[well].tolist()[rowNum] - df_all_data_wells_temp_tubing_pivot[well].tolist()[rowNum-40])/4\n",
    "\t\t\t\t\t\t\t\t\t\tif temp_tubing_4hr_slope <=-5:\n",
    "\t\t\t\t\t\t\t\t\t\t\tdeadheadEventDetected = True\n",
    "\t\t\t\t\t\t\t\t\t\t\ttubingTempPriorToDeadhead = df_all_data_wells_temp_tubing_pivot[well].tolist()[rowNum-40]\n",
    "\t\t\t\t\t\t\t\t\t\t\tdate = df_all_data_wells_temp_tubing_pivot.index.tolist()[rowNum-40]\n",
    "\t\t\t\t\t\t\t\t\t\t\tlastDeadheadDate = date\n",
    "\t\t\t\t\t\t\t\t\t\t\t#print(lastDeadheadDate)\n",
    "\t\t\t\t\t\t\t\t\t\t\t#input('')\n",
    "\t\t\t\t\t\t\t\t\t\t\tannotation = well + ' NFE'\n",
    "\n",
    "\t\t\t\t\t\t\t\t\t\t\ttrip_dates.append(date)\n",
    "\t\t\t\t\t\t\t\t\t\t\ttrip_desc.append(annotation)\n",
    "\t\t\t\t\t\t\t\t\t\t\tall_events.append({'well':well, 'date': date.strftime('%Y-%m-%d %X'), 'desc': annotation}) #############\n",
    "\n",
    "\t\t\t\t\t\t\t\t\t\t\tprint('deadhead event found. ', 'current temp: ', df_all_data_wells_temp_tubing_pivot[well].tolist()[rowNum], '. temp @-4hrs: ', df_all_data_wells_temp_tubing_pivot[well].tolist()[rowNum-40], '. slope:', temp_tubing_4hr_slope, '. Date: ', date)\n",
    "\n",
    "\t\t\t\t\t\t\t\t\t\t\tfig.add_trace(go.Scatter(\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tx=[date], y=[df_all_data_pads_pg['value'].loc[df_all_data_pads_pg['date']==date].tolist()[0]],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tmode='markers + text',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tmarker=dict(\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tcolor='blue',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tsize=10,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\ttext = [well],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\ttextposition=\"middle left\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\ttextfont=dict(\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tfamily=\"sans serif\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tsize=8,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tcolor='blue'\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tmarker_symbol = 'x',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tname=annotation, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\tlegendgroup = well),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tsecondary_y=False,\n",
    "\t\t\t\t\t\t\t\t\t\t\t)\t\t\t\t\t\t\t\n",
    "\n",
    "\t\t\t\t\t\t\t\t\t\t\t# fig.add_annotation(text=well, x=date, y=df_all_data_pads_pg['value'].loc[df_all_data_pads_pg['date']==date].tolist()[0], showarrow=False, textangle=-90,\n",
    "\t\t\t\t\t\t\t\t\t\t\t# \tfont=dict(\n",
    "\t\t\t\t\t\t\t\t\t\t\t# \t\tfamily=\"sans serif\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t# \t\tsize=8,\n",
    "\t\t\t\t\t\t\t\t\t\t\t# \t\tcolor='blue'\n",
    "\t\t\t\t\t\t\t\t\t\t\t# \t), yshift = 20)\n",
    "\n",
    "\n",
    "\t\t\t\t\t\t\t\texcept:\n",
    "\t\t\t\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\tif rowNum >=10:\n",
    "\t\t\t\t\t\t\tif df_all_data_wells_esp_frequency_pivot[well].tolist()[rowNum] - df_all_data_wells_esp_frequency_pivot[well].tolist()[rowNum-10] >2:\n",
    "\t\t\t\t\t\t\t\tif speedUpEventsDetected ==False:\n",
    "\t\t\t\t\t\t\t\t\t#create new lists to enter data during the speed up event. \n",
    "\t\t\t\t\t\t\t\t\tspeedUpDates = []\n",
    "\t\t\t\t\t\t\t\t\tspeedUpEmulsionVals = []\n",
    "\t\t\t\t\t\t\t\t\tspeedUpESPSpeeds = []\n",
    "\t\t\t\t\t\t\t\t\t#this is the first detection and we will put in all 10pts used to make this realization that a speed up is occuring. Afterwards only the new point\n",
    "\t\t\t\t\t\t\t\t\ti = rowNum-10 \n",
    "\t\t\t\t\t\t\t\t\twhile i <= rowNum:\n",
    "\t\t\t\t\t\t\t\t\t\tdate = df_all_data_wells_esp_frequency_pivot.index.tolist()[i]\n",
    "\t\t\t\t\t\t\t\t\t\tspeedUpDates.append(date)\n",
    "\t\t\t\t\t\t\t\t\t\t#speedUpEmulsionVals.append(df_all_data_pads_emulsion['value'].loc[df_all_data_pads_emulsion['date']==date].tolist()[0])\n",
    "\t\t\t\t\t\t\t\t\t\tspeedUpESPSpeeds.append(df_all_data_wells_esp_frequency_pivot[well].tolist()[i])\n",
    "\t\t\t\t\t\t\t\t\t\ti=i+1\n",
    "\t\t\t\t\t\t\t\t\tspeedUpEventsDetected = True\n",
    "\t\t\t\t\t\t\t\telif speedUpEventsDetected ==True:\n",
    "\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\t\tdate = df_all_data_wells_esp_frequency_pivot.index.tolist()[rowNum]\n",
    "\t\t\t\t\t\t\t\t\tspeedUpDates.append(date)\n",
    "\t\t\t\t\t\t\t\t\t#speedUpEmulsionVals.append(df_all_data_pads_emulsion['value'].loc[df_all_data_pads_emulsion['date']==date].tolist()[0])\n",
    "\t\t\t\t\t\t\t\t\tspeedUpESPSpeeds.append(df_all_data_wells_esp_frequency_pivot[well].tolist()[rowNum])\n",
    "\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\tif speedUpEventsDetected ==True:\n",
    "\t\t\t\t\t\t\t\t\tfreqChange = speedUpESPSpeeds[len(speedUpESPSpeeds)-1]-speedUpESPSpeeds[0]\n",
    "\t\t\t\t\t\t\t\t\tif freqChange < 25: #this indicates a start up and it will already be captured in other anontations. \n",
    "\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\t\t\tannotation = well + ' +' + str(round(freqChange,2)) + ' hz'\n",
    "\t\t\t\t\t\t\t\t\t\tprint(annotation)\n",
    "\t\t\t\t\t\t\t\t\t\t#print('line prior to speed up print statement zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz')\n",
    "\t\t\t\t\t\t\t\t\t\t#print(annotation)\n",
    "\t\t\t\t\t\t\t\t\t\t#print(speedUpDates)\n",
    "\t\t\t\t\t\t\t\t\t\t#print(speedUpESPSpeeds)\n",
    "\t\t\t\t\t\t\t\t\t\t#print('line after to speed up print statement zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz')\n",
    "\t\t\t\t\t\t\t\t\t\tstart_dates.append(speedUpDates[0])\n",
    "\t\t\t\t\t\t\t\t\t\tstart_desc.append(annotation)\n",
    "\t\t\t\t\t\t\t\t\t\tall_events.append({'well':well, 'date': date.strftime('%Y-%m-%d %X'), 'desc': annotation}) #############\n",
    "\n",
    "\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\t\t\t#!!!!!!!!!!!!!!!!! - - uncomment to insert emulsion line to plot -- --!!!!!!!!!\n",
    "\t\t\t\t\t\t\t\t\t\t# fig.add_trace(go.Scatter(\n",
    "\t\t\t\t\t\t\t\t\t\t# \tx=[speedUpDates[0], speedUpDates[len(speedUpESPSpeeds)-1]],\n",
    "\t\t\t\t\t\t\t\t\t\t# \ty=[max(speedUpEmulsionVals), max(speedUpEmulsionVals)],\n",
    "\t\t\t\t\t\t\t\t\t\t# \tmode='lines',\n",
    "\t\t\t\t\t\t\t\t\t\t# \tline=dict(\n",
    "\t\t\t\t\t\t\t\t\t\t# \t\tcolor='red',\n",
    "\t\t\t\t\t\t\t\t\t\t# \t\t),\n",
    "\t\t\t\t\t\t\t\t\t\t# \tname=annotation),\n",
    "\t\t\t\t\t\t\t\t\t\t# \tsecondary_y=True,\n",
    "\t\t\t\t\t\t\t\t\t\t# )\n",
    "\t\t\t\t\t\t\t\t\t\t#!!!!!!!!!!!!!!!!! - - uncomment to insert emulsion line to plot -- --!!!!!!!!!\n",
    "\t\t\t\t\t\t\t\t\tspeedUpEventsDetected =False\n",
    "\n",
    "\t\t\t\t\texcept:\n",
    "\t\t\t\t\t\tprevVal = currentVal\n",
    "\t\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t\tprevVal = currentVal\n",
    "\t\t\n",
    "\n",
    "\t\t####Write main PG plot to png\n",
    "\n",
    "\t\tscale_input = 5\n",
    "\n",
    "\t\tfig.update_layout(width=600, height = 300, showlegend=False, margin=dict(l= 0, r= 0, t=0, b=0))\n",
    "\t\tfig.update_xaxes(range=[(endDate - dateutil.relativedelta.relativedelta(days = 14)), endDate])\n",
    "\t\t#fig.show()\n",
    "\t\t#fig.write_image(rootDir + \"/prod_report_images/\" + mp + \"_pg_plot.png\", format=\"png\", scale=scale_input, engine=\"kaleido\") \n",
    "\t\t#fig.write_html(rootDir + \"/prod_report_images/\" + mp + \"_pg_plot.html\")\n",
    "\t\t\n",
    "\t\t#write tables\n",
    "\t\t#table generic set up inputs:\n",
    "\t\theader_height = 19\n",
    "\t\theader_font_size = 13\n",
    "\t\tcells_height=19\n",
    "\t\tcells_font_size=11\n",
    "\n",
    "\t\t#create trips / nfe table: \n",
    "\t\ttemp_sorting_df = pd.DataFrame(data={'date': trip_dates, 'vals': trip_desc})\n",
    "\t\ttemp_sorting_df['date'] = pd.to_datetime(temp_sorting_df['date'])\n",
    "\t\ttemp_sorting_df = temp_sorting_df[~(temp_sorting_df['date'] < (endDate - dateutil.relativedelta.relativedelta(days = 1)))]\n",
    "\t\ttemp_sorting_df = temp_sorting_df.sort_values(by='date', ascending = True)\n",
    "\t\touterWhileLoopCount = 0\n",
    "\t\twhile len(temp_sorting_df) > 8: #need to search for group trips and / or delete\n",
    "\t\t\touterWhileLoopCount = outerWhileLoopCount +1\n",
    "\t\t\tlinesThatAreNotSingleTrips = 0 \n",
    "\t\t\tfor index, row in temp_sorting_df.iterrows():\n",
    "\t\t\t\tif 'trip' in row['vals'] and 'trips' not in row['vals']: #trip detected\n",
    "\t\t\t\t\tindexListToDelete = []\n",
    "\t\t\t\t\treferenceDate = row['date']\n",
    "\t\t\t\t\treferenceIndex = index\n",
    "\t\t\t\t\tcountOfNearbyTrips = 0\t\n",
    "\t\t\t\t\tfor index, row in temp_sorting_df.iterrows():\n",
    "\t\t\t\t\t\tif index != referenceIndex and 'trip' in row['vals'] and 'trips' not in row['vals']:\n",
    "\t\t\t\t\t\t\tdateDiff = row['date'] - referenceDate\n",
    "\t\t\t\t\t\t\tdays, seconds = dateDiff.days, dateDiff.seconds\n",
    "\t\t\t\t\t\t\thoursDiff = days * 24 + seconds // 3600\n",
    "\t\t\t\t\t\t\tif hoursDiff <=3:\n",
    "\t\t\t\t\t\t\t\tcountOfNearbyTrips = countOfNearbyTrips +1\n",
    "\t\t\t\t\t\t\t\tindexListToDelete.append(index)\n",
    "\t\t\t\t\tif countOfNearbyTrips >0:\n",
    "\t\t\t\t\t\tindexListToDelete.append(referenceIndex)\n",
    "\t\t\t\t\t\ttemp_sorting_df = temp_sorting_df.drop(indexListToDelete)\n",
    "\t\t\t\t\t\ttemp = pd.DataFrame(data={'date': [referenceDate], 'vals': [\"Trips (\" + str(countOfNearbyTrips) + \")\"]})\n",
    "\t\t\t\t\t\t#print(temp_sorting_df)\n",
    "\t\t\t\t\t\t#print(temp)\n",
    "\t\t\t\t\t\t#input('')\n",
    "\t\t\t\t\t\ttemp_sorting_df=pd.concat([temp_sorting_df, temp])\n",
    "\t\t\t\t\t\ttemp_sorting_df = temp_sorting_df.sort_values(by='date', ascending = True)\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tlinesThatAreNotSingleTrips = linesThatAreNotSingleTrips +1\n",
    "\t\t\t\t\tif linesThatAreNotSingleTrips == len(temp_sorting_df) or outerWhileLoopCount == 8:\n",
    "\t\t\t\t\t\ttemp_sorting_df = temp_sorting_df.sort_values(by='date', ascending = False)\n",
    "\t\t\t\t\t\t#print(temp_sorting_df)\n",
    "\t\t\t\t\t\tn=len(temp_sorting_df)-8+1\n",
    "\t\t\t\t\t\ttemp_sorting_df = temp_sorting_df.iloc[:-n , :]\n",
    "\t\t\t\t\t\ttemp = pd.DataFrame(data={'date': [endDate - dateutil.relativedelta.relativedelta(days = 1)], 'vals': [\"Overflow...\"]})\n",
    "\t\t\t\t\t\ttemp_sorting_df=pd.concat([temp_sorting_df, temp])\n",
    "\t\t\t\t\t\t#print(temp_sorting_df)\n",
    "\t\t\t\t\t\t#input('lines were dropped from table')\n",
    "\t\t\t\t\t\tbreak\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t\ttemp_sorting_df = temp_sorting_df.sort_values(by='date', ascending = False)\n",
    "\n",
    "\t\tdatestrs = [dt.datetime.strftime(x,'%b-%d %H:%M') for x in temp_sorting_df['date'].tolist()]\n",
    "\n",
    "\t\tvalues = []\n",
    "\t\tvalues.append(datestrs)\n",
    "\t\tvalues.append(temp_sorting_df['vals'].tolist())\n",
    "\n",
    "\t\ttable_fig = go.Figure(data=[go.Table(\n",
    "\t\tcolumnorder = [1,2],\n",
    "\t\tcolumnwidth = [1,1.6],\n",
    "\t\theader = dict(\n",
    "\t\t\tvalues = ['Date', 'Event'],\n",
    "\t\t\tline_color='darkslategray',\n",
    "\t\t\tfill_color='royalblue',\n",
    "\t\t\talign=['center','center'],\n",
    "\t\t\tfont=dict(color='white', size=header_font_size),\n",
    "\t\t\theight=header_height\n",
    "\t\t),\n",
    "\t\tcells=dict(\n",
    "\t\t\tvalues=values,\n",
    "\t\t\tline_color='darkslategray',\n",
    "\t\t\tfill=dict(color=['paleturquoise', 'white']),\n",
    "\t\t\talign=['left', 'center'],\n",
    "\t\t\tfont_size=cells_font_size,\n",
    "\t\t\theight=cells_height)\n",
    "\t\t\t)\n",
    "\t\t])\n",
    "\n",
    "\t\theightCalc = (len(datestrs) * cells_height) +header_height +2\n",
    "\t\ttable_fig.update_layout(width=300, height = heightCalc, margin=dict(l= 0, r= 0, t=0, b=0))\n",
    "\t\t#table_fig.write_image(rootDir + \"/prod_report_images/\" + mp + \"_trip_nfe.png\", format=\"png\", scale=scale_input, engine=\"kaleido\") \n",
    "\n",
    "\t\t#create starts/speed ups table: \n",
    "\t\ttemp_sorting_df = pd.DataFrame(data={'date': start_dates, 'vals': start_desc})\n",
    "\t\ttemp_sorting_df['date'] = pd.to_datetime(temp_sorting_df['date'])\n",
    "\t\ttemp_sorting_df = temp_sorting_df[~(temp_sorting_df['date'] < (endDate - dateutil.relativedelta.relativedelta(days = 1)))]\n",
    "\t\ttemp_sorting_df = temp_sorting_df.sort_values(by='date', ascending = True)\n",
    "\n",
    "\t\touterWhileLoopCount = 0\n",
    "\t\twhile len(temp_sorting_df) > 8: #need to search for group trips and / or delete\n",
    "\t\t\touterWhileLoopCount = outerWhileLoopCount +1\n",
    "\n",
    "\t\t\tlinesThatAreNotSingleStarts = 0 \n",
    "\t\t\tfor index, row in temp_sorting_df.iterrows():\n",
    "\t\t\t\tif 'start' in row['vals'] and 'starts' not in row['vals']: #trip detected\n",
    "\t\t\t\t\tindexListToDelete = []\n",
    "\t\t\t\t\treferenceDate = row['date']\n",
    "\t\t\t\t\treferenceIndex = index\n",
    "\t\t\t\t\tcountOfNearbyStarts = 0\t\n",
    "\t\t\t\t\tfor index, row in temp_sorting_df.iterrows():\n",
    "\t\t\t\t\t\tif index != referenceIndex and 'start' in row['vals'] and 'starts' not in row['vals']:\n",
    "\t\t\t\t\t\t\tdateDiff = row['date'] - referenceDate\n",
    "\t\t\t\t\t\t\tdays, seconds = dateDiff.days, dateDiff.seconds\n",
    "\t\t\t\t\t\t\thoursDiff = days * 24 + seconds // 3600\n",
    "\t\t\t\t\t\t\tif hoursDiff <=3:\n",
    "\t\t\t\t\t\t\t\tcountOfNearbyStarts = countOfNearbyStarts +1\n",
    "\t\t\t\t\t\t\t\tindexListToDelete.append(index)\n",
    "\t\t\t\t\tif countOfNearbyStarts >0:\n",
    "\t\t\t\t\t\tindexListToDelete.append(referenceIndex)\n",
    "\t\t\t\t\t\ttemp_sorting_df = temp_sorting_df.drop(indexListToDelete)\n",
    "\t\t\t\t\t\ttemp = pd.DataFrame(data={'date': [referenceDate], 'vals': [\"Starts (\" + str(countOfNearbyStarts) + \")\"]})\n",
    "\t\t\t\t\t\t#print(temp_sorting_df)\n",
    "\t\t\t\t\t\t#print(temp)\n",
    "\t\t\t\t\t\t#input('')\n",
    "\t\t\t\t\t\ttemp_sorting_df=pd.concat([temp_sorting_df, temp])\n",
    "\t\t\t\t\t\ttemp_sorting_df = temp_sorting_df.sort_values(by='date', ascending = True)\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tlinesThatAreNotSingleStarts = linesThatAreNotSingleStarts +1\n",
    "\t\t\t\t\tif linesThatAreNotSingleStarts == len(temp_sorting_df) or outerWhileLoopCount == 8:\n",
    "\t\t\t\t\t\ttemp_sorting_df = temp_sorting_df.sort_values(by='date', ascending = False)\n",
    "\t\t\t\t\t\t#print(temp_sorting_df)\n",
    "\t\t\t\t\t\t#input('')\n",
    "\t\t\t\t\t\tn=len(temp_sorting_df)-8+1\n",
    "\t\t\t\t\t\ttemp_sorting_df = temp_sorting_df.iloc[:-n , :]\n",
    "\t\t\t\t\t\t#temp_sorting_df = temp_sorting_df.drop(df.tail(len(temp_sorting_df)-(8+1)).index, inplace = True)\n",
    "\t\t\t\t\t\t#print(temp_sorting_df)\n",
    "\t\t\t\t\t\ttemp = pd.DataFrame(data={'date': [endDate - dateutil.relativedelta.relativedelta(days = 1)], 'vals': [\"Overflow...\"]})\n",
    "\t\t\t\t\t\ttemp_sorting_df=pd.concat([temp_sorting_df, temp])\n",
    "\t\t\t\t\t\t#print(temp_sorting_df)\n",
    "\t\t\t\t\t\t#input('lines were dropped from table')\n",
    "\t\t\t\t\t\tbreak\n",
    "\n",
    "\n",
    "\t\ttemp_sorting_df = temp_sorting_df.sort_values(by='date', ascending = False)\n",
    "\t\tdatestrs = [dt.datetime.strftime(x,'%b-%d %H:%M') for x in temp_sorting_df['date'].tolist()]\n",
    "\n",
    "\t\tvalues = []\n",
    "\t\tvalues.append(datestrs)\n",
    "\t\tvalues.append(temp_sorting_df['vals'].tolist())\n",
    "\n",
    "\t\ttable_fig = go.Figure(data=[go.Table(\n",
    "\t\tcolumnorder = [1,2],\n",
    "\t\tcolumnwidth = [1,1.5],\n",
    "\t\theader = dict(\n",
    "\t\t\tvalues = ['Date', 'Event'],\n",
    "\t\t\tline_color='darkslategray',\n",
    "\t\t\tfill_color='royalblue',\n",
    "\t\t\talign=['center','center'],\n",
    "\t\t\tfont=dict(color='white', size=header_font_size),\n",
    "\t\t\theight=header_height\n",
    "\t\t),\n",
    "\t\tcells=dict(\n",
    "\t\t\tvalues=values,\n",
    "\t\t\tline_color='darkslategray',\n",
    "\t\t\tfill=dict(color=['paleturquoise', 'white']),\n",
    "\t\t\talign=['center', 'center'],\n",
    "\t\t\tfont_size=cells_font_size,\n",
    "\t\t\theight=cells_height)\n",
    "\t\t\t)\n",
    "\t\t])\n",
    "\n",
    "\t\theightCalc = (len(datestrs) * cells_height) +header_height +2\n",
    "\t\ttable_fig.update_layout(width=300, height = heightCalc, margin=dict(l= 0, r= 0, t=0, b=0))\n",
    "\t\t#table_fig.write_image(rootDir + \"/prod_report_images/\" + mp+ \"_start_speedup.png\", format=\"png\", scale=scale_input, engine=\"kaleido\") \n",
    "\n",
    "\t\t#create overall rate of change table\n",
    "\n",
    "\t\tvalues = []\n",
    "\t\tfor col in df_pg_roc_data.columns:\n",
    "\t\t\tvalues.append(df_pg_roc_data[col].tolist())\n",
    "\t\t\n",
    "\t\t#values.append(datestrs)\n",
    "\t\t#values.append(temp_sorting_df['vals'].tolist())\n",
    "\n",
    "\t\ttable_fig = go.Figure(data=[go.Table(\n",
    "\t\tcolumnorder = [1,2,3,4],\n",
    "\t\tcolumnwidth = [1, 0.75, 0.75, 0.75],\n",
    "\t\theader = dict(\n",
    "\t\t\tvalues = df_pg_roc_data.columns,\n",
    "\t\t\tline_color='darkslategray',\n",
    "\t\t\tfill_color='royalblue',\n",
    "\t\t\talign=['center','center'],\n",
    "\t\t\tfont=dict(color='white', size=header_font_size),\n",
    "\t\t\theight=header_height\n",
    "\t\t),\n",
    "\t\tcells=dict(\n",
    "\t\t\tvalues=values,\n",
    "\t\t\tline_color='darkslategray',\n",
    "\t\t\tfill=dict(color=['paleturquoise', 'white']),\n",
    "\t\t\talign=['center', 'center'],\n",
    "\t\t\tfont_size=cells_font_size,\n",
    "\t\t\theight=cells_height)\n",
    "\t\t\t)\n",
    "\t\t])\n",
    "\n",
    "\t\theightCalc = (len(df_pg_roc_data['mp']) * cells_height) +header_height +2\n",
    "\t\ttable_fig.update_layout(width=250, height = heightCalc, margin=dict(l= 0, r= 0, t=0, b=0))\n",
    "\t\t#table_fig.write_image(rootDir + \"/prod_report_images/mp_pg_roc.png\", format=\"png\", scale=scale_input, engine=\"kaleido\") \n",
    "\n",
    "\t\t#create casing valve average position table\n",
    "\n",
    "\t\tdf_csg_valve_data = df_csg_valve_data.sort_values(by=str(well_csg_valve_lookback_list[0])+\"d\", ascending = False)\n",
    "\t\tn=len(df_csg_valve_data)-8\n",
    "\t\tdf_csg_valve_data = df_csg_valve_data.iloc[:-n , :]\n",
    "\n",
    "\n",
    "\t\tvalues = []\n",
    "\t\tfor col in df_csg_valve_data.columns:\n",
    "\t\t\tvalues.append(df_csg_valve_data[col].tolist())\n",
    "\t\t\n",
    "\t\t#values.append(datestrs)\n",
    "\t\t#values.append(temp_sorting_df['vals'].tolist())\n",
    "\n",
    "\t\ttable_fig = go.Figure(data=[go.Table(\n",
    "\t\tcolumnorder = [1,2,3,4],\n",
    "\t\tcolumnwidth = [1, 1, 1, 1],\n",
    "\t\theader = dict(\n",
    "\t\t\tvalues = df_csg_valve_data.columns,\n",
    "\t\t\tline_color='darkslategray',\n",
    "\t\t\tfill_color='royalblue',\n",
    "\t\t\talign=['center','center'],\n",
    "\t\t\tfont=dict(color='white', size=header_font_size),\n",
    "\t\t\theight=header_height\n",
    "\t\t),\n",
    "\t\tcells=dict(\n",
    "\t\t\tvalues=values,\n",
    "\t\t\tline_color='darkslategray',\n",
    "\t\t\tfill=dict(color=['paleturquoise', 'white']),\n",
    "\t\t\talign=['center', 'center'],\n",
    "\t\t\tfont_size=cells_font_size,\n",
    "\t\t\theight=cells_height)\n",
    "\t\t\t)\n",
    "\t\t])\n",
    "\n",
    "\t\theightCalc = (len(df_csg_valve_data['Well']) * cells_height) +header_height +2\n",
    "\t\ttable_fig.update_layout(width=300, height = heightCalc, margin=dict(l= 0, r= 0, t=0, b=0))\n",
    "\t\t#table_fig.write_image(rootDir + \"/prod_report_images/\" + mp + \"_csg_valve.png\", format=\"png\", scale=scale_input, engine=\"kaleido\")\n",
    "\t\t# Open a file in write mode.\n",
    "\t\n",
    "\tprint(all_events) \n",
    "\twith open('events.csv', 'w') as f:\n",
    "\t\t# Write all the dictionary keys in a file with commas separated.\n",
    "\t\tf.write(','.join(all_events[0].keys()))\n",
    "\t\tf.write('\\n') # Add a new line\n",
    "\t\tfor row in all_events:\n",
    "\t\t\t# Write the values in a row.\n",
    "\t\t\tf.write(','.join(str(x) for x in row.values()))\n",
    "\t\t\tf.write('\\n') # Add a new line\n",
    "\n",
    "\t\n",
    "\n",
    "\tprint('images are created. Starting creating report to PDF.')\n",
    "\t#py_create_pdf_report.create_report()\n",
    "\n",
    "\tf = open(rootDir + \"/Log.txt\",\"a+\")\n",
    "\tf.write(\"\\r\\n\")\n",
    "\tstr_msg = str(dt.datetime.today()) + \" - Code is complete\"\n",
    "\tf.write(str_msg + \"\\r\\n\")\n",
    "\tf.write(\"-----------------------------------\\r\\n\")\n",
    "\tf.write(\"\\r\\n\")\n",
    "\tf.close()\n",
    "\tprint('script complete')\n",
    "except:\n",
    "\tprint(traceback.format_exc())\n",
    "\tf = open(rootDir + \"/Log.txt\",\"a+\")\n",
    "\tf.write(\"\\r\\n\")\n",
    "\tf.write(str(dt.datetime.today()) + \"\\r\\n\")\n",
    "\tf.write(str(traceback.format_exc()) + \"\\r\\n\")\n",
    "\tf.write(\"\\r\\n\")\n",
    "\tf.write(\"-----------------------------------\\r\\n\")\n",
    "\tf.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Trips = red triangle\n",
    "- Starts - green triangle\n",
    "- NFEs = blue X "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
